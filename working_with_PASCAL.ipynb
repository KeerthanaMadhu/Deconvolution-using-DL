{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm,binom\n",
    "from scipy.io import loadmat\n",
    "from scipy.special import digamma, gammaln, gamma\n",
    "from numpy.linalg import inv\n",
    "#import cv2\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_load import Image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = Image_data(npyfilename1 = 'PASCAL_data.npy',npyfilename2 = 'gray_scale.npy',\n",
    "                        kernel_file_name = 'kernel1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data.original_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data.normalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_data.conv_images[48542],cmap = 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_data.original_images[48542],cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_noisy[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01960784, 0.02352941, 0.04705882, 0.06666667,\n",
       "       0.07058824, 0.07843138, 0.08627451, 0.09411765, 0.10196079,\n",
       "       0.10588235, 0.14901961, 0.15294118, 0.16470589, 0.1764706 ,\n",
       "       0.18431373, 0.19215687, 0.19607843, 0.25490198, 0.25882354,\n",
       "       0.28627452, 0.3019608 , 0.3137255 , 0.37254903, 0.38039216,\n",
       "       0.3882353 , 0.40784314, 0.41568628, 0.42352942, 0.43137255,\n",
       "       0.4509804 , 0.45490196, 0.45882353, 0.49019608, 0.5019608 ,\n",
       "       0.5647059 , 0.58431375, 0.5882353 , 0.60784316, 0.62352943,\n",
       "       0.627451  , 0.63529414, 0.6392157 , 0.6509804 , 0.65882355,\n",
       "       0.6627451 , 0.6862745 , 0.6901961 , 0.69411767, 0.74509805,\n",
       "       0.7529412 , 0.7607843 , 0.78039217, 0.8039216 , 0.8117647 ,\n",
       "       0.84313726, 0.85490197, 0.85882354, 0.87058824, 0.8745098 ,\n",
       "       0.8901961 , 0.89411765, 0.9019608 , 0.9098039 , 0.91764706,\n",
       "       0.92156863, 0.9647059 , 0.96862745, 0.9764706 , 0.98039216,\n",
       "       0.9843137 , 0.9882353 , 0.99215686, 0.99607843], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(x_train[298])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "\n",
    "\n",
    "plt.imshow(x_train[298].reshape(28, 28),cmap = 'gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[28].reshape(28, 28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_test_noisy[298])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (7, 7, 32)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 28,353\n",
      "Trainable params: 28,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0942 - val_loss: 0.0944\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0943 - val_loss: 0.0947\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0942 - val_loss: 0.0937\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0941 - val_loss: 0.0937\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0941 - val_loss: 0.0941\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0942 - val_loss: 0.0938\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0941 - val_loss: 0.0940\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0941 - val_loss: 0.0938\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0941 - val_loss: 0.0939\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0940 - val_loss: 0.0936\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0941 - val_loss: 0.0941\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0941 - val_loss: 0.0944\n",
      "Epoch 13/100\n",
      " 4736/60000 [=>............................] - ETA: 6s - loss: 0.0940"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-50b11af22f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 callbacks=[TensorBoard(log_dir='/tmp/tb')])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/dlenv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/dlenv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dlenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dlenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dlenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/tb')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_noisy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1161781822029413"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000/28353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
